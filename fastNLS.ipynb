{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy.linalg as sla\n",
    "import tensors.synthetic_tensors as synthetic_tensors\n",
    "import backend.numpy_ext as tenpy\n",
    "from CPD.common_kernels import get_residual, compute_lin_sys\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive NLS Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian3(A):\n",
    "    J = np.zeros((Q,order*s*R))\n",
    "    for i in range(order):\n",
    "        offset1 = i*s*R\n",
    "        for j in range(R):\n",
    "            offset2 = j*s\n",
    "            start = offset1+offset2\n",
    "            end = start + s\n",
    "            if i==0:\n",
    "                J[:,start:end] = np.kron(np.identity(s),np.kron(A[1][:,j],A[2][:,j])).T\n",
    "            elif i==1:\n",
    "                J[:,start:end] = np.kron(A[0][:,j],np.kron(np.identity(s),A[2][:,j])).T\n",
    "            elif i==2:\n",
    "                J[:,start:end] = np.kron(A[0][:,j],np.kron(A[1][:,j],np.identity(s))).T\n",
    "    return J\n",
    "\n",
    "def F(T,A):\n",
    "    f = (T - np.einsum(\"ir,jr,kr->ijk\",A[0],A[1],A[2])).reshape(-1)\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(T,A):\n",
    "    g = np.zeros(order*s*R)\n",
    "    G = []\n",
    "    \n",
    "    TC = tenpy.einsum(\"ijk,ka->ija\",T,A[2])\n",
    "    M1 = tenpy.einsum(\"ija,ja->ia\",TC,A[1])\n",
    "    G1 = -1*M1 + np.dot(A[0],compute_lin_sys(tenpy,A[1],A[2],0))\n",
    "    G.append(G1)\n",
    "    \n",
    "    M2 = tenpy.einsum(\"ija,ia->ja\",TC,A[0])\n",
    "    G2 = -1*M2 + np.dot(A[1],compute_lin_sys(tenpy,A[0],A[2],0))\n",
    "    G.append(G2)\n",
    "    \n",
    "    M3 = tenpy.einsum(\"ijk,ia,ja->ka\",T,A[0],A[1])\n",
    "    G3 = -1*M3 + np.dot(A[2],compute_lin_sys(tenpy,A[0],A[1],0))\n",
    "    G.append(G3)\n",
    "    \n",
    "    for i in range(order):\n",
    "        offset1 = i*s*R\n",
    "        for j in range(R):\n",
    "            offset2 = j*s\n",
    "            start = offset1 + offset2\n",
    "            end = start + s\n",
    "            g[start:end] = G[i][:,j]\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_A(A):\n",
    "    a = np.zeros(order*R*s)\n",
    "    for i in range(order):\n",
    "        offset1 = i*s*R\n",
    "        for j in range(R):\n",
    "            offset2 = j*s\n",
    "            start = offset1+offset2\n",
    "            end = start+s\n",
    "            a[start:end] = A[i][:,j]\n",
    "    return a\n",
    "\n",
    "def update_A(A,x):\n",
    "    for i in range(order):\n",
    "        offset1 = i*s*R\n",
    "        for j in range(R):\n",
    "            offset2 = j*s\n",
    "            start = offset1+offset2\n",
    "            end = start+s\n",
    "            A[i][:,j] += x[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast NLS Implementation with Block Matrix-Vector Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast Hessian approximation by Gauss-Newton\n",
    "def compute_coeff(G,n1,r1,n2,r2):\n",
    "    return np.prod([G[i][r1,r2] for i in range(len(G)) if i!=n1 and i!=n2])\n",
    "        \n",
    "def compute_block(A,G,n1,r1,n2,r2):\n",
    "    if n1 == n2:\n",
    "        return compute_coeff(G,n1,r1,n2,r2)*np.identity(A[0].shape[0])\n",
    "    else:\n",
    "        return compute_coeff(G,n1,r1,n2,r2)*np.outer(A[n1][:,r2],A[n2][:,r1])\n",
    "\n",
    "def fast_hessian3(A):\n",
    "    G1 = A[0].T.dot(A[0])\n",
    "    G2 = A[1].T.dot(A[1])\n",
    "    G3 = A[2].T.dot(A[2])\n",
    "    G = [G1,G2,G3]\n",
    "    N = order*s*R\n",
    "    hessian = np.zeros((N,N))\n",
    "    \n",
    "    for n1 in range(order):\n",
    "        for r1 in range(R):\n",
    "            startv = n1*R*s + r1*s\n",
    "            endv = startv + s\n",
    "            for n2 in range(order):\n",
    "                for r2 in range(R):\n",
    "                    starth = n2*R*s + r2*s\n",
    "                    endh = starth + s\n",
    "                    hessian[startv:endv,starth:endh] = compute_block(A,G,n1,r1,n2,r2)\n",
    "    return hessian\n",
    "\n",
    "def compute_result_block(A,G,n1,r1,n2,r2,x):\n",
    "    if n1==n2:\n",
    "        return compute_coeff(G,n1,r1,n2,r2)*x\n",
    "    else:\n",
    "        s = compute_coeff(G,n1,r1,n2,r2)*np.inner(A[n2][:,r1],x)\n",
    "        return s*A[n1][:,r2]\n",
    "\n",
    "def fast_hessian3_mult(A,x,regu=1):\n",
    "    ret = regu*x\n",
    "    G = []\n",
    "    for i in range(len(A)):\n",
    "        G.append(A[i].T.dot(A[i]))\n",
    "    \n",
    "    for n1 in range(order):\n",
    "        for r1 in range(R):\n",
    "            startv = n1*R*s + r1*s\n",
    "            endv = startv + s\n",
    "            for n2 in range(order):\n",
    "                for r2 in range(R):\n",
    "                    starth = n2*R*s + r2*s\n",
    "                    endh = starth + s\n",
    "                    ret[startv:endv] += compute_result_block(A,G,n1,r1,n2,r2,x[starth:endh])\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient(A,x,b,tol=1e-5):\n",
    "    r = b - A.dot(x)\n",
    "    if la.norm(r)<tol:\n",
    "        return x\n",
    "    p = r\n",
    "    counter = 0\n",
    "    while True:\n",
    "        alpha = np.inner(r,r)/np.inner(p,A.dot(p))\n",
    "        x += alpha*p\n",
    "        r_new = r - alpha*A.dot(p)\n",
    "        if la.norm(r_new)<tol:\n",
    "            break\n",
    "        beta = np.inner(r_new,r_new)/np.inner(r,r)\n",
    "        p = r_new + beta*p\n",
    "        r = r_new\n",
    "        counter += 1\n",
    "    print(\"conjugate gradient took \",counter,\" iteration(s).\")\n",
    "    return x,counter\n",
    "\n",
    "def preconditioned_conjugate_gradient(A,x,b,M,tol=1e-5,formula=\"PR\"):\n",
    "    r = b - A.dot(x)\n",
    "    if la.norm(r)<tol:\n",
    "        return x\n",
    "    z = M.dot(r)\n",
    "    p = z\n",
    "    counter = 0\n",
    "    while True:\n",
    "        alpha = np.inner(r,z)/np.inner(p,A.dot(p))\n",
    "        x += alpha*p\n",
    "        r_new = r - alpha*A.dot(p)\n",
    "        if la.norm(r_new)<tol: ## need to add max iteration\n",
    "            break\n",
    "        z_new = M.dot(r_new)\n",
    "        if formula == \"PR\":\n",
    "            beta = np.inner(z_new,r_new-r)/np.inner(z,r)\n",
    "        else:\n",
    "            beta = np.inner(z_new,r_new)/np.inner(z,r)\n",
    "        p = z_new + beta*p\n",
    "        r = r_new\n",
    "        z = z_new\n",
    "        counter += 1\n",
    "    print(\"conjugate gradient took \",counter,\" iteration(s).\")\n",
    "    return x,counter\n",
    "\n",
    "\n",
    "def fast_conjugate_gradient():\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_block_preconditioner(H,order,stride):\n",
    "    M = np.zeros(H.shape)\n",
    "    for i in range(order):\n",
    "        start = i*stride\n",
    "        end = start + stride\n",
    "        M[start:end,start:end] = H[start:end,start:end]\n",
    "    L = la.cholesky(M)\n",
    "    Y = sla.solve_triangular(L,np.identity(H.shape[0]),trans=0,lower=True)\n",
    "    X = sla.solve_triangular(L,Y,trans=1,lower=True)\n",
    "    return X\n",
    "\n",
    "def naive_block_preconditioner2(G):\n",
    "    N = order*s*R\n",
    "    ret = np.zeros((N,N))\n",
    "    n = s*R\n",
    "    X = np.zeros((n,n)) #X should be indexed by n1,r1,n2,r2; n: range(R), r: range(s)\n",
    "    I = np.eye(s)\n",
    "    \n",
    "    # form X\n",
    "    # do Cholesky on X\n",
    "    # invert two factors by tri-solve\n",
    "    # form the inverse by kronecker product\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive NLS implementation for order 3 CP decomposition\n",
    "order = 3\n",
    "s = 4\n",
    "R = 6\n",
    "sp_frac = 1\n",
    "iteration = 20\n",
    "\n",
    "[T,O] = synthetic_tensors.init_rand(tenpy,order,s,R,sp_frac)\n",
    "A = []\n",
    "for i in range(T.ndim):\n",
    "    A.append(tenpy.random((T.shape[i],R)))\n",
    "\n",
    "Q = s**order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Residual computation took', 0.00011730194091796875, 'seconds')\n",
      "Start residual is  4.264598812881373\n",
      "x shape is (72,)\n",
      "[ 0 ] iteration gradient norm is  20.276611145438107\n",
      "conjugate gradient took  24  iteration(s).\n",
      "('Residual computation took', 8.368492126464844e-05, 'seconds')\n",
      "[ 0 ] iteration residual is  1.1480816000247636\n",
      "[ 1 ] iteration gradient norm is  2.4158674719623385\n",
      "conjugate gradient took  25  iteration(s).\n",
      "('Residual computation took', 8.559226989746094e-05, 'seconds')\n",
      "[ 1 ] iteration residual is  0.5340810789357322\n",
      "[ 2 ] iteration gradient norm is  0.3939618372231854\n",
      "conjugate gradient took  27  iteration(s).\n",
      "('Residual computation took', 8.869171142578125e-05, 'seconds')\n",
      "[ 2 ] iteration residual is  0.2997238056422972\n",
      "[ 3 ] iteration gradient norm is  0.16141677546777994\n",
      "conjugate gradient took  30  iteration(s).\n",
      "('Residual computation took', 7.081031799316406e-05, 'seconds')\n",
      "[ 3 ] iteration residual is  0.22149628549548708\n",
      "[ 4 ] iteration gradient norm is  0.0628994369597153\n",
      "conjugate gradient took  31  iteration(s).\n",
      "('Residual computation took', 5.984306335449219e-05, 'seconds')\n",
      "[ 4 ] iteration residual is  0.18790980475340027\n",
      "[ 5 ] iteration gradient norm is  0.03860287303215426\n",
      "conjugate gradient took  33  iteration(s).\n",
      "('Residual computation took', 6.508827209472656e-05, 'seconds')\n",
      "[ 5 ] iteration residual is  0.16387749858812586\n",
      "[ 6 ] iteration gradient norm is  0.030454810398450653\n",
      "conjugate gradient took  27  iteration(s).\n",
      "('Residual computation took', 6.67572021484375e-05, 'seconds')\n",
      "[ 6 ] iteration residual is  0.14335330898424217\n",
      "[ 7 ] iteration gradient norm is  0.024947101658863467\n",
      "conjugate gradient took  29  iteration(s).\n",
      "('Residual computation took', 7.367134094238281e-05, 'seconds')\n",
      "[ 7 ] iteration residual is  0.12691754210476647\n",
      "[ 8 ] iteration gradient norm is  0.019333747967207396\n",
      "conjugate gradient took  31  iteration(s).\n",
      "('Residual computation took', 6.198883056640625e-05, 'seconds')\n",
      "[ 8 ] iteration residual is  0.1152093068731926\n",
      "[ 9 ] iteration gradient norm is  0.01437118679762561\n",
      "conjugate gradient took  31  iteration(s).\n",
      "('Residual computation took', 5.125999450683594e-05, 'seconds')\n",
      "[ 9 ] iteration residual is  0.1071626501937475\n",
      "[ 10 ] iteration gradient norm is  0.010854255667556288\n",
      "conjugate gradient took  29  iteration(s).\n",
      "('Residual computation took', 6.031990051269531e-05, 'seconds')\n",
      "[ 10 ] iteration residual is  0.1011031408397912\n",
      "[ 11 ] iteration gradient norm is  0.008846852533334195\n",
      "conjugate gradient took  31  iteration(s).\n",
      "('Residual computation took', 0.0002846717834472656, 'seconds')\n",
      "[ 11 ] iteration residual is  0.0957273399556488\n",
      "[ 12 ] iteration gradient norm is  0.007959026579513952\n",
      "conjugate gradient took  31  iteration(s).\n",
      "('Residual computation took', 7.009506225585938e-05, 'seconds')\n",
      "[ 12 ] iteration residual is  0.09028794831178345\n",
      "[ 13 ] iteration gradient norm is  0.007649641758261191\n",
      "conjugate gradient took  29  iteration(s).\n",
      "('Residual computation took', 6.937980651855469e-05, 'seconds')\n",
      "[ 13 ] iteration residual is  0.08453078997740943\n",
      "[ 14 ] iteration gradient norm is  0.007424681204812054\n",
      "conjugate gradient took  28  iteration(s).\n",
      "('Residual computation took', 6.914138793945312e-05, 'seconds')\n",
      "[ 14 ] iteration residual is  0.07866238101494652\n",
      "[ 15 ] iteration gradient norm is  0.0069470970345239195\n",
      "conjugate gradient took  30  iteration(s).\n",
      "('Residual computation took', 6.866455078125e-05, 'seconds')\n",
      "[ 15 ] iteration residual is  0.07321921604915935\n",
      "[ 16 ] iteration gradient norm is  0.0061083916192412185\n",
      "conjugate gradient took  33  iteration(s).\n",
      "('Residual computation took', 7.748603820800781e-05, 'seconds')\n",
      "[ 16 ] iteration residual is  0.06871547534621068\n",
      "[ 17 ] iteration gradient norm is  0.005044277220578458\n",
      "conjugate gradient took  35  iteration(s).\n",
      "('Residual computation took', 6.890296936035156e-05, 'seconds')\n",
      "[ 17 ] iteration residual is  0.06531640856895467\n",
      "[ 18 ] iteration gradient norm is  0.004004778491787168\n",
      "conjugate gradient took  36  iteration(s).\n",
      "('Residual computation took', 6.890296936035156e-05, 'seconds')\n",
      "[ 18 ] iteration residual is  0.062845606444224\n",
      "[ 19 ] iteration gradient norm is  0.0031678607854545367\n",
      "conjugate gradient took  35  iteration(s).\n",
      "('Residual computation took', 6.914138793945312e-05, 'seconds')\n",
      "[ 19 ] iteration residual is  0.0610071834825841\n",
      "Total number of CG iterations is  605\n"
     ]
    }
   ],
   "source": [
    "res = get_residual(tenpy,T,A)\n",
    "print(\"Start residual is \",res)\n",
    "x = flatten_A(A)\n",
    "print(\"x shape is\",x.shape)\n",
    "a = 0\n",
    "for i in range(iteration):\n",
    "    J = jacobian3(A)\n",
    "    #f = F(T,A)\n",
    "    JT = np.transpose(J)\n",
    "    regu = 1/(i+1)\n",
    "    H = np.dot(JT,J) + regu*np.identity(J.shape[1])\n",
    "    #plt.matshow(np.isclose(H,0))\n",
    "    #plt.show()\n",
    "    #M = np.diag(1/np.diag(H))\n",
    "    #H = fast_hessian3(A,regu)\n",
    "    \n",
    "    b = -1*gradient(T,A)\n",
    "    print(\"[\",i,\"] iteration gradient norm is \",la.norm(b))\n",
    "    M = naive_block_preconditioner(H,order,s*R)\n",
    "    #b = np.dot(JT,f)\n",
    "    #L = la.cholesky(H)\n",
    "    #y = sla.solve_triangular(L,b,trans=0,lower=True)\n",
    "    #x = sla.solve_triangular(L,y,trans=1,lower=True)\n",
    "    #x = la.solve(H,b)\n",
    "    #x,c = conjugate_gradient(H,x,b)\n",
    "    x,c = preconditioned_conjugate_gradient(H,x,b,M)\n",
    "    a += c\n",
    "    update_A(A,x)\n",
    "    res = get_residual(tenpy,T,A)\n",
    "    print(\"[\",i,\"] iteration residual is \",res)\n",
    "print(\"Total number of CG iterations is \",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast NLS Implementation with Tensor Contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coefficient_matrix(G,n1,n2):\n",
    "    ret = np.ones(G[0].shape)\n",
    "    for i in range(len(G)):\n",
    "        if i!=n1 and i!=n2:\n",
    "            ret = np.einsum(\"ij,ij->ij\",ret,G[i])\n",
    "    return ret\n",
    "\n",
    "def fast_hessian_contract(A,X):\n",
    "    N = len(A)\n",
    "    ## Preprocessing step: should be moved outside of contraction \n",
    "    G = []\n",
    "    for mat in A:\n",
    "        G.append(mat.T.dot(mat))\n",
    "    \n",
    "    ret = []\n",
    "    for n in range(N):\n",
    "        for p in range(N):\n",
    "            ## Computation of M should be done outside of contraction\n",
    "            M = compute_coefficient_matrix(G,n,p)\n",
    "            if n==p:\n",
    "                Y = np.einsum(\"iz,zr->ir\",X[p],M)\n",
    "            else:\n",
    "                B = np.einsum(\"jr,jz->rz\",A[p],X[p])\n",
    "                Y = np.einsum(\"iz,zr,rz->ir\",A[n],M,B)\n",
    "            if p==0:\n",
    "                ret.append(Y)\n",
    "            else:\n",
    "                ret[n] += Y\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "X = [np.random.random((s,R)) for i in range(order)]\n",
    "x = flatten_A(X)\n",
    "J = jacobian3(A)\n",
    "JT = np.transpose(J)\n",
    "H = np.dot(JT,J)\n",
    "r1 = H.dot(x)\n",
    "r2 = flatten_A(fast_hessian_contract(A,X))\n",
    "print(np.isclose(r1,r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
