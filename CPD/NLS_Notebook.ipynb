{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "import scipy.sparse.linalg as spsalg\n",
    "import backend.numpy_ext as tenpy\n",
    "import CPD.standard_ALS3 as stnd_ALS\n",
    "from CPD.common_kernels import solve_sys, compute_lin_sys\n",
    "import CPD.common_kernels as ck\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.utilities.iterables import multiset_permutations\n",
    "\n",
    "def measure_dist(a,b,c,A,B,C):\n",
    "    A= flipsign(tenpy,A)\n",
    "    A = A/np.linalg.norm(A,axis=0)\n",
    "    B = flipsign(tenpy,B)\n",
    "    B = B/np.linalg.norm(B,axis=0)\n",
    "    C = flipsign(tenpy,C)\n",
    "    C = C/np.linalg.norm(C,axis=0)\n",
    "    ind = []\n",
    "    \n",
    "    \n",
    "    nums= np.arange(a.shape[1])\n",
    "\n",
    "\n",
    "    a = a/np.linalg.norm(a,axis=0)\n",
    "    b = b/np.linalg.norm(b,axis=0)\n",
    "    c = c/np.linalg.norm(c,axis=0)\n",
    "\n",
    "    for perm in multiset_permutations(nums):\n",
    "        norm = np.linalg.norm(A[:,perm]-a)\n",
    "        ind.append([perm,norm])\n",
    "\n",
    "\n",
    "    ind = np.array(ind)\n",
    "    val_index = np.argmin(ind[:,1])\n",
    "    norm = ind[:,1][val_index]\n",
    "\n",
    "    norm2 = np.linalg.norm(B[:,(ind[:,0][val_index])] - b)\n",
    "    norm3 = np.linalg.norm(C[:,(ind[:,0][val_index])] - c)\n",
    "\n",
    "    return(norm,norm2,norm3)\n",
    "\n",
    "def equilibrate(A,B,C):\n",
    "    norm1 = np.linalg.norm(A,axis=0)\n",
    "    norm2 = np.linalg.norm(B,axis =0)\n",
    "    norm3 = np.linalg.norm(C,axis =0)\n",
    "    delta = (norm1*norm2*norm3)**(1/3)\n",
    "    A = A*delta/norm1\n",
    "    B = B*delta/norm2\n",
    "    C = C*delta/norm3\n",
    "    return [A,B,C]\n",
    "\n",
    "def flipsign(tenpy, U):\n",
    "    \"\"\"\n",
    "    Flip sign of factor matrices such that largest magnitude\n",
    "    element will be positive\n",
    "    \"\"\"\n",
    "    midx = tenpy.argmax(U, axis=0)\n",
    "    for i in range(U.shape[1]):\n",
    "        if U[int(midx[i]), i] < 0:\n",
    "            U[:, i] = -U[:, i]\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Jxxdel(X,loc,delta):\n",
    "    n = len(X)\n",
    "    s= X[loc].shape[0]\n",
    "    R = X[loc].shape[1]\n",
    "    D = np.ones((R,R))\n",
    "    for i in range(n):\n",
    "        if i == loc:\n",
    "            continue\n",
    "        else:\n",
    "            D = np.einsum('ij,ij->ij',np.einsum('kr,kz->rz',X[i],X[i]),D)\n",
    "    \n",
    "    prod = np.einsum('iz,zr->ir',delta,D)\n",
    "    return prod\n",
    "\n",
    "\n",
    "def compute_Jxydel(X,loc1,loc2,delta):\n",
    "    n = len(X)\n",
    "    R = X[loc1].shape[1]\n",
    "    D = np.ones((R,R))\n",
    "    for i in range(n):\n",
    "        if i == loc1 or i == loc2:\n",
    "            continue\n",
    "        else:\n",
    "            D = np.einsum('ij,ij->ij',np.einsum('kr,kz->rz',X[i],X[i]),D)\n",
    "            \n",
    "    temp = np.einsum(\"jr,jz->rz\",X[loc2],delta)\n",
    "    prod = np.einsum(\"iz,zr,rz->ir\",X[loc1],D,temp)\n",
    "    \n",
    "    return prod\n",
    "\n",
    "\n",
    "def compute_JTJdel(X,delta):\n",
    "    K = np.zeros_like(delta)\n",
    "    n = len(X)\n",
    "    for j in range(n):\n",
    "        K[j] = compute_Jxxdel(X,j,delta[j])\n",
    "        for i in range(n):\n",
    "            if i ==j:\n",
    "                continue\n",
    "            else:\n",
    "                K[j]+= compute_Jxydel(X,j,i,delta[i])\n",
    "\n",
    "    return K\n",
    "\n",
    "def einstr(order,contract_index,wrt_index):\n",
    "    if wrt_index == order-1 and contract_index == wrt_index-1:\n",
    "        str1 =\"\".join(['R' for j in range(order-2)])\n",
    "        str1= str1+ \"\".join([chr(ord('a')+contract_index)])+ \"\".join([chr(ord('a')+wrt_index)])\n",
    "        \n",
    "        str2 = \"\".join([chr(ord('a')+contract_index)])+'R'\n",
    "        str3 = \"\".join([chr(ord('a')+wrt_index)])+'R'\n",
    "        \n",
    "    elif contract_index == order-1:\n",
    "        str1 =\"\".join(['R' for j in range(order-1)])\n",
    "        str1= str1+ \"\".join([chr(ord('a')+contract_index)])\n",
    "        ls = list(str1)\n",
    "        ls[wrt_index] = \"\".join([chr(ord('a')+wrt_index)])\n",
    "        str1 = \"\".join(ls)\n",
    "        \n",
    "        str2 = \"\".join([chr(ord('a')+contract_index)])+'R'\n",
    "        str3 = \"\".join([chr(ord('a')+wrt_index)])+'R'\n",
    "    else:\n",
    "        str1= \"\".join([chr(ord('a')+j) for j in range(order)])\n",
    "        str2= \"\".join([chr(ord('a')+contract_index)])+'R'\n",
    "        str3= str1.replace(\"\".join([chr(ord('a')+contract_index)]),'R')\n",
    "    \n",
    "    string = str1+','+str2 +'->'+str3\n",
    "    \n",
    "    \n",
    "    return string\n",
    "\n",
    "def flatten_Tensor(G,order,s,R):\n",
    "    g = np.zeros(order*s*R)\n",
    "    for i in range(order):\n",
    "        offset1 = i*s*R\n",
    "        for j in range(R):\n",
    "            offset2 = j*s\n",
    "            start = offset1 + offset2\n",
    "            end = start + s\n",
    "            g[start:end] = G[i][:,j]\n",
    "    return g\n",
    "\n",
    "def gen_gradient(X,T):\n",
    "    order = T.ndim\n",
    "    out = np.zeros_like(X)\n",
    "\n",
    "    for i in range(order):\n",
    "        inter = T.copy()\n",
    "        R = out[i].shape[1]\n",
    "        s = out[i].shape[0]\n",
    "        D = np.ones((R,R))\n",
    "        for j in range(order):\n",
    "            if i != j:\n",
    "                inter = np.einsum(einstr(order,j,i),inter,X[j])\n",
    "                D = np.einsum('ij,ij->ij',np.einsum('kr,kz->rz',X[j],X[j]),D)\n",
    "                \n",
    "        out[i] = -inter + X[i]@D\n",
    "        \n",
    "    return flatten_Tensor(out,order,s,R)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_LinOp(X,Regu):\n",
    "    n = len(X)\n",
    "    s = X[0].shape[0]\n",
    "    R= X[0].shape[1]\n",
    "    \n",
    "    def mv(delta):\n",
    "        delta = compute_matrices(delta,s,R)\n",
    "        K = np.zeros_like(delta)\n",
    "        for j in range(n):\n",
    "            K[j] = compute_Jxxdel(X,j,delta[j])\n",
    "            for i in range(n):\n",
    "                if i ==j:\n",
    "                    continue\n",
    "                else:\n",
    "                    K[j]+= compute_Jxydel(X,j,i,delta[i])\n",
    "                    \n",
    "            K[j]+= Regu*delta[j]\n",
    "        vec = flatten_Tensor(K,n,s,R)\n",
    "        return vec \n",
    "    \n",
    "    V = LinearOperator(shape = (n*s*R,n*s*R), matvec=mv)\n",
    "    return V\n",
    "\n",
    "def compute_matrices(x,s,R):\n",
    "    A = x[:s*R].reshape(s,R,order= 'F')\n",
    "    B = x[s*R:2*s*R].reshape(s,R,order='F')\n",
    "    C = x[2*s*R:3*s*R].reshape(s,R,order='F')\n",
    "    \n",
    "    return [A,B,C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Residual computation took', 0.0008265972137451172, 'seconds')\n",
      "Residual is 378.19795630318845\n",
      "starting NLS\n",
      "NLS Iterations: 11\n",
      "Time taken 1.200024127960205\n",
      "('Residual computation took', 0.0, 'seconds')\n",
      "Residual is 2.3843969824633834e-12\n",
      "Total cg iterations 1918\n",
      "--------------------\n",
      "('Residual computation took', 0.0009980201721191406, 'seconds')\n",
      "Residual is 378.19795630318845\n",
      "starting NLS\n",
      "NLS Iterations: 14\n",
      "Time taken for atol 0.44803881645202637\n",
      "('Residual computation took', 0.0009615421295166016, 'seconds')\n",
      "Residual with atol is 2.6964940720154707e-06\n",
      "Total cg iterations with atol 530\n",
      "--------------------\n",
      "******************\n"
     ]
    }
   ],
   "source": [
    "s =20\n",
    "\n",
    "#for R in [40,41,42]:\n",
    "num_gen = 1\n",
    "\n",
    "R = 10\n",
    "als_iter = 10000\n",
    "\n",
    "max_iter = 250\n",
    "num_init = 1\n",
    "\n",
    "for k in range(num_gen):\n",
    "    \n",
    "    a = np.random.randn(s,R)\n",
    "    b = np.random.randn(s,R)\n",
    "    c = np.random.randn(s,R)\n",
    "    \n",
    "    T = np.einsum('ia,ja,ka->ijk', a,b,c)\n",
    "    \n",
    "    \n",
    "    for j in range(num_init):\n",
    "        A = np.random.randn(s,R)\n",
    "        K = A.copy()\n",
    "        P = A.copy()\n",
    "\n",
    "        B = np.random.randn(s,R)\n",
    "        O = B.copy()\n",
    "        Q = B.copy()\n",
    "\n",
    "        C = np.random.randn(s,R)\n",
    "        M = C.copy()\n",
    "        N = C.copy()\n",
    "\n",
    "        state = np.random.get_state()\n",
    "\n",
    "        X = np.array([A,B,C])\n",
    "\n",
    "        global cg_iters\n",
    "\n",
    "        cg_iters=0\n",
    "\n",
    "        def cg_call(v):\n",
    "            global cg_iters\n",
    "            cg_iters= cg_iters+1\n",
    "\n",
    "        \n",
    "        X = np.array([A,B,C])\n",
    "        \n",
    "        \n",
    "        res = ck.get_residual3(tenpy,T,X[0],X[1],X[2])\n",
    "        print('Residual is',res)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        print('starting NLS')\n",
    "        start = time.time()\n",
    "        for i in range(max_iter):\n",
    "            Regu = 10**-6\n",
    "            tolerance = 10**-6\n",
    "            L= create_LinOp(X,Regu)\n",
    "            [delta,_] = spsalg.cg(L,-gen_gradient(X,T), tol= tolerance,callback=cg_call)\n",
    "            delta = np.array(compute_matrices(delta,s,R))\n",
    "            X+=delta\n",
    "            #res = ck.get_residual3(tenpy,T,X[0],X[1],X[2])\n",
    "            #print('Residual is',res)\n",
    "            if np.linalg.norm(delta.reshape(-1), ord= np.inf)<10**-6:\n",
    "                print('NLS Iterations:',i)\n",
    "                break\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Time taken\",end-start)\n",
    "        res = ck.get_residual3(tenpy,T,X[0],X[1],X[2])\n",
    "        #print('state is',state)\n",
    "        print('Residual is',res)\n",
    "        print('Total cg iterations',cg_iters)\n",
    "        print('--------------------')\n",
    "        \n",
    "        \n",
    "        \n",
    "        X = np.array([P,Q,N])\n",
    "\n",
    "\n",
    "        cg_iters=0\n",
    "\n",
    "        def cg_call(v):\n",
    "            global cg_iters\n",
    "            cg_iters= cg_iters+1\n",
    "        \n",
    "        \n",
    "        res = ck.get_residual3(tenpy,T,X[0],X[1],X[2])\n",
    "        print('Residual is',res)\n",
    "\n",
    "        last_norm = None\n",
    "        \n",
    "\n",
    "        print('starting NLS')\n",
    "        start = time.time()\n",
    "        for i in range(max_iter):\n",
    "            Regu = 10**-6\n",
    "            tolerance = 10**-6\n",
    "            L= create_LinOp(X,Regu)\n",
    "            g = gen_gradient(X,T)\n",
    "            [delta,_] = spsalg.cg(L,-g, tol= tolerance,callback=cg_call,atol = last_norm)\n",
    "            delta = np.array(compute_matrices(delta,s,R))\n",
    "            last_norm = np.linalg.norm(delta)\n",
    "            X+=delta\n",
    "            #res = ck.get_residual3(tenpy,T,X[0],X[1],X[2])\n",
    "            #print('Residual is',res)\n",
    "            if np.linalg.norm(g.reshape(-1))<10**-4:\n",
    "                print('NLS Iterations:',i)\n",
    "                break\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Time taken for atol\",end-start)\n",
    "        res = ck.get_residual3(tenpy,T,X[0],X[1],X[2])\n",
    "        #print('state is',state)\n",
    "        print('Residual with atol is',res)\n",
    "        print('Total cg iterations with atol',cg_iters)\n",
    "        print('--------------------')\n",
    "        \n",
    "                \n",
    "     \n",
    "    print('******************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CPD.common_kernels import compute_number_of_variables, flatten_Tensor, reshape_into_matrices, solve_sys\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "import scipy.sparse.linalg as spsalg\n",
    "\n",
    "try:\n",
    "    import Queue as queue\n",
    "except ImportError:\n",
    "    import queue\n",
    "\n",
    "def fast_hessian_contract(tenpy,X,A,gamma,regu=1):\n",
    "    N = len(A)\n",
    "    ret = []\n",
    "    for n in range(N):\n",
    "        for p in range(N):\n",
    "            M = gamma[n][p]\n",
    "            if n==p:\n",
    "                Y = tenpy.einsum(\"iz,zr->ir\",X[p],M)\n",
    "            else:\n",
    "                Y = tenpy.einsum(\"iz,zr,jr,jz->ir\",A[n],M,A[p],X[p])\n",
    "            if p==0:\n",
    "                ret.append(Y)\n",
    "            else:\n",
    "                ret[n] += Y\n",
    "\n",
    "    for i in range(N):\n",
    "        ret[i] += regu*X[i]\n",
    "    return ret\n",
    "\n",
    "def fast_block_diag_precondition(tenpy,X,P):\n",
    "    N = len(X)\n",
    "    ret = []\n",
    "    for i in range(N):\n",
    "        Y = tenpy.solve_tri(P[i], X[i], True, False, True)\n",
    "        Y = tenpy.solve_tri(P[i], Y, True, False, False)\n",
    "        ret.append(Y)\n",
    "    return ret\n",
    "\n",
    "class CP_fastNLS_Optimizer():\n",
    "    \"\"\"Fast Nonlinear Least Square Method for CP is a novel method of\n",
    "    computing the CP decomposition of a tensor by utilizing tensor contractions\n",
    "    and preconditioned conjugate gradient to speed up the process of solving\n",
    "    damped Gauss-Newton problem of CP decomposition.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,tenpy,T,A,cg_tol=1e-4,args=None):\n",
    "        self.tenpy = tenpy\n",
    "        self.T = T\n",
    "        self.A = A\n",
    "        self.cg_tol = cg_tol\n",
    "        self.G = None\n",
    "        self.gamma = None\n",
    "        self.last_step_norm = None\n",
    "\n",
    "\n",
    "    def _einstr_builder(self,M,s,ii):\n",
    "        ci = \"\"\n",
    "        nd = M.ndim\n",
    "        if len(s) != 1:\n",
    "            ci =\"R\"\n",
    "            nd = M.ndim-1\n",
    "\n",
    "        str1 = \"\".join([chr(ord('a')+j) for j in range(nd)])+ci\n",
    "        str2 = (chr(ord('a')+ii))+\"R\"\n",
    "        str3 = \"\".join([chr(ord('a')+j) for j in range(nd) if j != ii])+\"R\"\n",
    "        einstr = str1 + \",\" + str2 + \"->\" + str3\n",
    "        return einstr\n",
    "\n",
    "    def compute_G(self):\n",
    "        G = []\n",
    "        for i in range(len(self.A)):\n",
    "            G.append(self.tenpy.einsum(\"ij,ik->jk\",self.A[i],self.A[i]))\n",
    "        self.G = G\n",
    "\n",
    "    def compute_coefficient_matrix(self,n1,n2):\n",
    "        ret = self.tenpy.ones(self.G[0].shape)\n",
    "        for i in range(len(self.G)):\n",
    "            if i!=n1 and i!=n2:\n",
    "                ret = self.tenpy.einsum(\"ij,ij->ij\",ret,self.G[i])\n",
    "        return ret\n",
    "\n",
    "    def compute_gamma(self):\n",
    "        N = len(self.A)\n",
    "        result = []\n",
    "        for i in range(N):\n",
    "            result.append([])\n",
    "            for j in range(N):\n",
    "                if j>=i:\n",
    "                    M = self.compute_coefficient_matrix(i,j)\n",
    "                    result[i].append(M)\n",
    "                else:\n",
    "                    M = result[j][i]\n",
    "                    result[i].append(M)\n",
    "        self.gamma = result\n",
    "\n",
    "    def compute_block_diag_preconditioner(self,Regu):\n",
    "        n = self.gamma[0][0].shape[0]\n",
    "        P = []\n",
    "        for i in range(len(self.A)):\n",
    "            P.append(self.tenpy.cholesky(self.gamma[i][i]+self.tenpy.eye(n)))\n",
    "        return P\n",
    "\n",
    "\n",
    "    def gradient(self):\n",
    "        grad = []\n",
    "        q = queue.Queue()\n",
    "        for i in range(len(self.A)):\n",
    "            q.put(i)\n",
    "        s = [(list(range(len(self.A))),self.T)]\n",
    "        while not q.empty():\n",
    "            i = q.get()\n",
    "            while i not in s[-1][0]:\n",
    "                s.pop()\n",
    "                assert(len(s) >= 1)\n",
    "            while len(s[-1][0]) != 1:\n",
    "                M = s[-1][1]\n",
    "                idx = s[-1][0].index(i)\n",
    "                ii = len(s[-1][0])-1\n",
    "                if idx == len(s[-1][0])-1:\n",
    "                    ii = len(s[-1][0])-2\n",
    "\n",
    "                einstr = self._einstr_builder(M,s,ii)\n",
    "\n",
    "                N = self.tenpy.einsum(einstr,M,self.A[ii])\n",
    "\n",
    "                ss = s[-1][0][:]\n",
    "                ss.remove(ii)\n",
    "                s.append((ss,N))\n",
    "            M = s[-1][1]\n",
    "            g = -1*M + self.A[i].dot(self.gamma[i][i])\n",
    "            grad.append(g)\n",
    "        return flatten_Tensor(self.tenpy,grad)\n",
    "\n",
    "\n",
    "    def create_fast_hessian_contract_LinOp(self,Regu):\n",
    "        num_var = compute_number_of_variables(self.A)\n",
    "        A = self.A\n",
    "        gamma = self.gamma\n",
    "        tenpy = self.tenpy\n",
    "        template = self.A\n",
    "\n",
    "        def mv(delta):\n",
    "            delta = reshape_into_matrices(tenpy,delta,template)\n",
    "            result = fast_hessian_contract(tenpy,delta,A,gamma,Regu)\n",
    "            vec = flatten_Tensor(tenpy,result)\n",
    "            return vec\n",
    "\n",
    "        V = LinearOperator(shape = (num_var,num_var), matvec=mv)\n",
    "        return V\n",
    "\n",
    "    def create_block_precondition_LinOp(self,P):\n",
    "        num_var = compute_number_of_variables(self.A)\n",
    "        tenpy = self.tenpy\n",
    "        template = self.A\n",
    "\n",
    "        def mv(delta):\n",
    "\n",
    "            delta = reshape_into_matrices(tenpy,delta,template)\n",
    "            result = fast_block_diag_precondition(tenpy,delta,P)\n",
    "            vec = flatten_Tensor(tenpy,result)\n",
    "            return vec\n",
    "\n",
    "        V = LinearOperator(shape = (num_var,num_var), matvec=mv)\n",
    "        return V\n",
    "\n",
    "    def update_A(self,delta):\n",
    "        for i in range(len(delta)):\n",
    "            self.A[i] += delta[i]\n",
    "\n",
    "\n",
    "\n",
    "    def step(self,Regu):\n",
    "        \"\"\"global cg_iters\n",
    "        def cg_call(v):\n",
    "            global cg_iters\n",
    "            cg_iters= cg_iters+1\n",
    "        \"\"\"\n",
    "\n",
    "        self.compute_G()\n",
    "        self.compute_gamma()\n",
    "        g = self.gradient()\n",
    "        mult_LinOp = self.create_fast_hessian_contract_LinOp(Regu)\n",
    "        #P = self.compute_block_diag_preconditioner(Regu)\n",
    "        #precondition_LinOp = self.create_block_precondition_LinOp(P)\n",
    "        [delta,_] = spsalg.cg(mult_LinOp,-1*g,tol=self.cg_tol,callback=None,atol=self.last_step_norm)\n",
    "        self.last_step_norm = self.tenpy.vecnorm(delta)\n",
    "        delta = reshape_into_matrices(self.tenpy,delta,self.A)\n",
    "        self.update_A(delta)\n",
    "        return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Residual computation took', 0.000993967056274414, 'seconds')\n",
      "Residual is 279.700007593367\n",
      "('Residual computation took', 0.0, 'seconds')\n",
      "Residual is 222.6140909461351\n",
      "('Residual computation took', 0.0011854171752929688, 'seconds')\n",
      "Residual is 230.82363911698064\n",
      "('Residual computation took', 0.0, 'seconds')\n",
      "Residual is 146.94323739734898\n",
      "('Residual computation took', 0.0010228157043457031, 'seconds')\n",
      "Residual is 186.3851770777031\n",
      "('Residual computation took', 0.0009398460388183594, 'seconds')\n",
      "Residual is 61.814473846521174\n",
      "('Residual computation took', 0.0009391307830810547, 'seconds')\n",
      "Residual is 26.303711915364385\n",
      "('Residual computation took', 0.0009999275207519531, 'seconds')\n",
      "Residual is 3.9885964694190004\n",
      "('Residual computation took', 0.0, 'seconds')\n",
      "Residual is 0.2972249597778691\n",
      "('Residual computation took', 0.0006496906280517578, 'seconds')\n",
      "Residual is 0.02615007104552042\n",
      "('Residual computation took', 0.0014495849609375, 'seconds')\n",
      "Residual is 0.007258679049673539\n",
      "('Residual computation took', 0.0, 'seconds')\n",
      "Residual is 0.0003589422811449359\n",
      "('Residual computation took', 0.0010037422180175781, 'seconds')\n",
      "Residual is 0.00018217884449513822\n",
      "('Residual computation took', 0.0, 'seconds')\n",
      "Residual is 2.7088016042054577e-06\n",
      "('Residual computation took', 0.0, 'seconds')\n",
      "Residual is 2.7088016042054577e-06\n",
      "NLS Iterations: 14\n",
      "Time taken for atol 2.098249912261963\n",
      "Residual is 2.7088016042054577e-06\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X = np.array([K,O,M])\n",
    "\n",
    "cg_iters=0\n",
    "\n",
    "opt = CP_fastNLS_Optimizer(tenpy,T,X,cg_tol=1e-6)\n",
    "\n",
    "for i in range(max_iter):\n",
    "\n",
    "    delta= np.array(opt.step(Regu))\n",
    "\n",
    "    res = ck.get_residual3(tenpy,T,X[0],X[1],X[2])\n",
    "    print('Residual is',res)\n",
    "\n",
    "    if np.linalg.norm(delta.reshape(-1),ord = np.inf)<10**-8:\n",
    "        print('NLS Iterations:',i)\n",
    "        break\n",
    "end = time.time()\n",
    "print(\"Time taken for atol\",end-start)\n",
    "print(\"Residual is\",res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
