{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CPD.common_kernels import compute_number_of_variables, flatten_Tensor, reshape_into_matrices, solve_sys\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "import scipy.sparse.linalg as spsalg\n",
    "import backend.numpy_ext as tenpy\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import Queue as queue\n",
    "except ImportError:\n",
    "    import queue\n",
    "\n",
    "def fast_hessian_contract(tenpy,X,A,gamma,regu=1):\n",
    "    N = len(A)\n",
    "    ret = []\n",
    "    for n in range(N):\n",
    "        for p in range(N):\n",
    "            M = gamma[n][p]\n",
    "            if n==p:\n",
    "                Y = tenpy.einsum(\"iz,zr->ir\",X[p],M)\n",
    "            else:\n",
    "                Y = tenpy.einsum(\"iz,zr,jr,jz->ir\",A[n],M,A[p],X[p])\n",
    "            if p==0:\n",
    "                ret.append(Y)\n",
    "            else:\n",
    "                ret[n] += Y\n",
    "\n",
    "    for i in range(N):\n",
    "        ret[i] += regu*X[i]\n",
    "    return ret\n",
    "\n",
    "def fast_block_diag_precondition(tenpy,X,P):\n",
    "    N = len(X)\n",
    "    ret = []\n",
    "    for i in range(N):\n",
    "        Y = tenpy.solve_tri(P[i], X[i], True, False, True)\n",
    "        Y = tenpy.solve_tri(P[i], Y, True, False, False)\n",
    "        ret.append(Y)\n",
    "    return ret\n",
    "\n",
    "class CP_fastNLS_Optimizer():\n",
    "    \"\"\"Fast Nonlinear Least Square Method for CP is a novel method of\n",
    "    computing the CP decomposition of a tensor by utilizing tensor contractions\n",
    "    and preconditioned conjugate gradient to speed up the process of solving\n",
    "    damped Gauss-Newton problem of CP decomposition.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,tenpy,T,A,cg_tol=1e-4,args=None):\n",
    "        self.tenpy = tenpy\n",
    "        self.T = T\n",
    "        self.A = A\n",
    "        self.cg_tol = cg_tol\n",
    "        self.G = None\n",
    "        self.gamma = None\n",
    "\n",
    "\n",
    "    def _einstr_builder(self,M,s,ii):\n",
    "        ci = \"\"\n",
    "        nd = M.ndim\n",
    "        if len(s) != 1:\n",
    "            ci =\"R\"\n",
    "            nd = M.ndim-1\n",
    "\n",
    "        str1 = \"\".join([chr(ord('a')+j) for j in range(nd)])+ci\n",
    "        str2 = (chr(ord('a')+ii))+\"R\"\n",
    "        str3 = \"\".join([chr(ord('a')+j) for j in range(nd) if j != ii])+\"R\"\n",
    "        einstr = str1 + \",\" + str2 + \"->\" + str3\n",
    "        return einstr\n",
    "\n",
    "    def compute_G(self):\n",
    "        G = []\n",
    "        for i in range(len(self.A)):\n",
    "            G.append(self.tenpy.einsum(\"ij,ik->jk\",self.A[i],self.A[i]))\n",
    "        self.G = G\n",
    "\n",
    "    def compute_coefficient_matrix(self,n1,n2):\n",
    "        ret = self.tenpy.ones(self.G[0].shape)\n",
    "        for i in range(len(self.G)):\n",
    "            if i!=n1 and i!=n2:\n",
    "                ret = self.tenpy.einsum(\"ij,ij->ij\",ret,self.G[i])\n",
    "        return ret\n",
    "\n",
    "    def compute_gamma(self):\n",
    "        N = len(self.A)\n",
    "        result = []\n",
    "        for i in range(N):\n",
    "            result.append([])\n",
    "            for j in range(N):\n",
    "                if j>=i:\n",
    "                    M = self.compute_coefficient_matrix(i,j)\n",
    "                    result[i].append(M)\n",
    "                else:\n",
    "                    M = result[j][i]\n",
    "                    result[i].append(M)\n",
    "        self.gamma = result\n",
    "\n",
    "    def compute_block_diag_preconditioner(self,Regu):\n",
    "        n = self.gamma[0][0].shape[0]\n",
    "        P = []\n",
    "        for i in range(len(self.A)):\n",
    "            P.append(self.tenpy.cholesky(self.gamma[i][i]+self.tenpy.eye(n)))\n",
    "        return P\n",
    "\n",
    "\n",
    "    def gradient(self):\n",
    "        grad = []\n",
    "        q = queue.Queue()\n",
    "        for i in range(len(self.A)):\n",
    "            q.put(i)\n",
    "        s = [(list(range(len(self.A))),self.T)]\n",
    "        while not q.empty():\n",
    "            i = q.get()\n",
    "            while i not in s[-1][0]:\n",
    "                s.pop()\n",
    "                assert(len(s) >= 1)\n",
    "            while len(s[-1][0]) != 1:\n",
    "                M = s[-1][1]\n",
    "                idx = s[-1][0].index(i)\n",
    "                ii = len(s[-1][0])-1\n",
    "                if idx == len(s[-1][0])-1:\n",
    "                    ii = len(s[-1][0])-2\n",
    "\n",
    "                einstr = self._einstr_builder(M,s,ii)\n",
    "\n",
    "                N = self.tenpy.einsum(einstr,M,self.A[ii])\n",
    "\n",
    "                ss = s[-1][0][:]\n",
    "                ss.remove(ii)\n",
    "                s.append((ss,N))\n",
    "            M = s[-1][1]\n",
    "            g = -1*M + self.A[i].dot(self.gamma[i][i])\n",
    "            grad.append(g)\n",
    "        return flatten_Tensor(self.tenpy,grad)\n",
    "\n",
    "\n",
    "    def create_fast_hessian_contract_LinOp(self,Regu):\n",
    "        num_var = compute_number_of_variables(self.A)\n",
    "        A = self.A\n",
    "        gamma = self.gamma\n",
    "        tenpy = self.tenpy\n",
    "        template = self.A\n",
    "\n",
    "        def mv(delta):\n",
    "            delta = reshape_into_matrices(tenpy,delta,template)\n",
    "            result = fast_hessian_contract(tenpy,delta,A,gamma,Regu)\n",
    "            vec = flatten_Tensor(tenpy,result)\n",
    "            return vec\n",
    "\n",
    "        V = LinearOperator(shape = (num_var,num_var), matvec=mv)\n",
    "        return V\n",
    "\n",
    "    def create_block_precondition_LinOp(self,P):\n",
    "        num_var = compute_number_of_variables(self.A)\n",
    "        tenpy = self.tenpy\n",
    "        template = self.A\n",
    "\n",
    "        def mv(delta):\n",
    "\n",
    "            delta = reshape_into_matrices(tenpy,delta,template)\n",
    "            result = fast_block_diag_precondition(tenpy,delta,P)\n",
    "            vec = flatten_Tensor(tenpy,result)\n",
    "            return vec\n",
    "\n",
    "        V = LinearOperator(shape = (num_var,num_var), matvec=mv)\n",
    "        return V\n",
    "\n",
    "    def update_A(self,delta):\n",
    "        for i in range(len(delta)):\n",
    "            self.A[i] += delta[i]\n",
    "\n",
    "    def step(self,Regu):\n",
    "        \"\"\"global cg_iters\n",
    "        def cg_call(v):\n",
    "            global cg_iters\n",
    "            cg_iters= cg_iters+1\n",
    "        \"\"\"\n",
    "        \n",
    "        self.compute_G()\n",
    "        self.compute_gamma()\n",
    "        g = self.gradient()\n",
    "        mult_LinOp = self.create_fast_hessian_contract_LinOp(Regu)\n",
    "        P = self.compute_block_diag_preconditioner(Regu)\n",
    "        precondition_LinOp = self.create_block_precondition_LinOp(P)\n",
    "        [delta,_] = spsalg.cg(mult_LinOp,-1*g,tol=self.cg_tol,M=precondition_LinOp,callback=None)\n",
    "        self.update_A(reshape_into_matrices(self.tenpy,delta,self.A))\n",
    "        return self.A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fbe08c36e4cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCP_fastNLS_Optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtenpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-57c3fc1f9fb5>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflatten_Tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtenpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "T = np.random.rand(5,5,5)\n",
    "A = np.random.rand(3,5,3)\n",
    "optimizer = CP_fastNLS_Optimizer(tenpy,T,A)\n",
    "optimizer\n",
    "optimizer.gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
